{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9790053,"sourceType":"datasetVersion","datasetId":5998844}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd \nmovies_df=pd.read_csv(r'/kaggle/input/movies/movies.csv')\nratings_df=pd.read_csv(r'/kaggle/input/movies/ratings.csv')","metadata":{"execution":{"iopub.status.busy":"2024-11-03T17:40:02.339372Z","iopub.execute_input":"2024-11-03T17:40:02.339823Z","iopub.status.idle":"2024-11-03T17:40:02.883867Z","shell.execute_reply.started":"2024-11-03T17:40:02.339782Z","shell.execute_reply":"2024-11-03T17:40:02.882874Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"print('The dimension of movies dataframe are:'),movies_df.shape,'The dimension of movies dataframe are:',ratings_df.shape","metadata":{"execution":{"iopub.status.busy":"2024-11-03T17:40:02.889682Z","iopub.execute_input":"2024-11-03T17:40:02.890071Z","iopub.status.idle":"2024-11-03T17:40:02.899879Z","shell.execute_reply.started":"2024-11-03T17:40:02.890031Z","shell.execute_reply":"2024-11-03T17:40:02.898883Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"The dimension of movies dataframe are:\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"(None, (9742, 3), 'The dimension of movies dataframe are:', (100836, 4))"},"metadata":{}}]},{"cell_type":"code","source":"movies_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-11-03T17:40:02.901131Z","iopub.execute_input":"2024-11-03T17:40:02.901481Z","iopub.status.idle":"2024-11-03T17:40:02.916648Z","shell.execute_reply.started":"2024-11-03T17:40:02.901429Z","shell.execute_reply":"2024-11-03T17:40:02.915376Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   movieId                               title  \\\n0        1                    Toy Story (1995)   \n1        2                      Jumanji (1995)   \n2        3             Grumpier Old Men (1995)   \n3        4            Waiting to Exhale (1995)   \n4        5  Father of the Bride Part II (1995)   \n\n                                        genres  \n0  Adventure|Animation|Children|Comedy|Fantasy  \n1                   Adventure|Children|Fantasy  \n2                               Comedy|Romance  \n3                         Comedy|Drama|Romance  \n4                                       Comedy  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>movieId</th>\n      <th>title</th>\n      <th>genres</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Toy Story (1995)</td>\n      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Jumanji (1995)</td>\n      <td>Adventure|Children|Fantasy</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Grumpier Old Men (1995)</td>\n      <td>Comedy|Romance</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Waiting to Exhale (1995)</td>\n      <td>Comedy|Drama|Romance</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Father of the Bride Part II (1995)</td>\n      <td>Comedy</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"ratings_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-11-03T17:40:02.919870Z","iopub.execute_input":"2024-11-03T17:40:02.920232Z","iopub.status.idle":"2024-11-03T17:40:02.933875Z","shell.execute_reply.started":"2024-11-03T17:40:02.920192Z","shell.execute_reply":"2024-11-03T17:40:02.932508Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   userId  movieId  rating  timestamp\n0       1        1     4.0  964982703\n1       1        3     4.0  964981247\n2       1        6     4.0  964982224\n3       1       47     5.0  964983815\n4       1       50     5.0  964982931","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userId</th>\n      <th>movieId</th>\n      <th>rating</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>4.0</td>\n      <td>964982703</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>3</td>\n      <td>4.0</td>\n      <td>964981247</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>6</td>\n      <td>4.0</td>\n      <td>964982224</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>47</td>\n      <td>5.0</td>\n      <td>964983815</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>50</td>\n      <td>5.0</td>\n      <td>964982931</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n","metadata":{"execution":{"iopub.status.busy":"2024-11-03T17:40:02.935313Z","iopub.execute_input":"2024-11-03T17:40:02.935689Z","iopub.status.idle":"2024-11-03T17:40:02.940911Z","shell.execute_reply.started":"2024-11-03T17:40:02.935651Z","shell.execute_reply":"2024-11-03T17:40:02.939695Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"movie_names=movies_df.set_index('movieId')['title'].to_dict()\nn_users=len(ratings_df.userId.unique())\nn_items=len(ratings_df.movieId.unique())\nprint(\"Number of unique users\",n_users)\nprint('The number of unique movies',n_items)\nprint('The full rating matrix will have:',n_users*n_items,'elements')\nprint('Therefore', len(ratings_df)/(n_users*n_items)*100 , 'percent of the matrix will be filled')","metadata":{"execution":{"iopub.status.busy":"2024-11-03T17:40:02.942323Z","iopub.execute_input":"2024-11-03T17:40:02.942735Z","iopub.status.idle":"2024-11-03T17:40:02.974832Z","shell.execute_reply.started":"2024-11-03T17:40:02.942665Z","shell.execute_reply":"2024-11-03T17:40:02.973650Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Number of unique users 610\nThe number of unique movies 9724\nThe full rating matrix will have: 5931640 elements\nTherefore 1.6999683055613624 percent of the matrix will be filled\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom torch.autograd import variable\nfrom tqdm import tqdm_notebook as tqdm\n#basic format of the matrix factorization where we initilize the embedding\nclass MaxFactorization(torch.nn.Module):\n    def __init__(self,n_users,n_items,n_factors=20):\n        super().__init__()\n        self.user_factors=torch.nn.Embedding(n_users,n_factors)#a lookup table for the input\n        self.item_factors=torch.nn.Embedding(n_items,n_factors)#lookup table for the input\n        self.user_factors.weight.data.uniform_(0,0.05)\n        self.item_factors.weight.data.uniform_(0,0.05)\n\n    def forward(self,data):\n        users, items =data[:,0], data[:,1]\n        return(self.user_factors(users)*self.item_factors(items)).sum(1)\n    def predict(self,user,item):\n        return self.forward(user,item)","metadata":{"execution":{"iopub.status.busy":"2024-11-03T17:40:02.976195Z","iopub.execute_input":"2024-11-03T17:40:02.976584Z","iopub.status.idle":"2024-11-03T17:40:04.934929Z","shell.execute_reply.started":"2024-11-03T17:40:02.976542Z","shell.execute_reply":"2024-11-03T17:40:04.933875Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data.dataset import Dataset\nfrom torch.utils.data import DataLoader\n\nclass Loader(Dataset):\n    def __init__(self):\n        self.ratings=ratings_df.copy()\n        \n        users = ratings_df.userId.unique()\n        movies=ratings_df.movieId.unique()\n\n        self.userid2idx= {o:i for i,o in enumerate(users)}\n        self.movieid2idx= {o:i for i,o in enumerate(movies)}\n        self.idx2userid = {i:o for o,i in self.userid2idx.items()}\n        self.idx2movieid={i:o for o,i in self.movieid2idx.items()}\n        \n        self.ratings.movieId= ratings_df.movieId.apply(lambda x: self.movieid2idx[x])\n        self.ratings.userId= ratings_df.userId.apply(lambda x: self.userid2idx[x])\n        \n        self.x=self.ratings.drop(['rating','timestamp'],axis=1).values\n        self.y=self.ratings['rating'].values\n        self.x,self.y= torch.tensor(self.x),torch.tensor(self.y)\n        \n        \n    def __getitem__(self,index):\n        return (self.x[index],self.y[index])\n    def __len__(self):\n        return len(self.ratings)\n\nprint('done')","metadata":{"execution":{"iopub.status.busy":"2024-11-03T17:40:04.936370Z","iopub.execute_input":"2024-11-03T17:40:04.937025Z","iopub.status.idle":"2024-11-03T17:40:04.950374Z","shell.execute_reply.started":"2024-11-03T17:40:04.936971Z","shell.execute_reply":"2024-11-03T17:40:04.949217Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"done\n","output_type":"stream"}]},{"cell_type":"code","source":"num_epochs = 128\ncuda = torch.cuda.is_available()\n\nprint('is running on GPU', cuda)\n\nmodel= MaxFactorization(n_users,n_items,n_factors=8)\nprint(model)\nfor name,param in model.named_parameters():\n    if param.requires_grad:\n        print(name,param.data)\n\nif cuda:\n    model=model.cuda()\n    \nloss_fn=torch.nn.MSELoss()\n\noptimizer=torch.optim.Adam(model.parameters(),lr=1e-3)\n\ntrain_set= Loader()\ntrain_loader= DataLoader(train_set,128,shuffle=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-03T17:40:04.952138Z","iopub.execute_input":"2024-11-03T17:40:04.952534Z","iopub.status.idle":"2024-11-03T17:40:06.192368Z","shell.execute_reply.started":"2024-11-03T17:40:04.952494Z","shell.execute_reply":"2024-11-03T17:40:06.191119Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"is running on GPU True\nMaxFactorization(\n  (user_factors): Embedding(610, 8)\n  (item_factors): Embedding(9724, 8)\n)\nuser_factors.weight tensor([[0.0132, 0.0238, 0.0460,  ..., 0.0042, 0.0160, 0.0199],\n        [0.0410, 0.0448, 0.0291,  ..., 0.0320, 0.0408, 0.0044],\n        [0.0079, 0.0231, 0.0054,  ..., 0.0438, 0.0161, 0.0338],\n        ...,\n        [0.0475, 0.0050, 0.0224,  ..., 0.0316, 0.0246, 0.0188],\n        [0.0164, 0.0437, 0.0104,  ..., 0.0009, 0.0414, 0.0030],\n        [0.0483, 0.0114, 0.0263,  ..., 0.0071, 0.0226, 0.0275]])\nitem_factors.weight tensor([[0.0098, 0.0007, 0.0459,  ..., 0.0140, 0.0333, 0.0352],\n        [0.0406, 0.0282, 0.0411,  ..., 0.0097, 0.0328, 0.0299],\n        [0.0151, 0.0224, 0.0027,  ..., 0.0394, 0.0125, 0.0471],\n        ...,\n        [0.0307, 0.0142, 0.0437,  ..., 0.0073, 0.0472, 0.0252],\n        [0.0445, 0.0453, 0.0213,  ..., 0.0014, 0.0132, 0.0159],\n        [0.0068, 0.0338, 0.0110,  ..., 0.0005, 0.0466, 0.0122]])\n","output_type":"stream"}]},{"cell_type":"code","source":"for it in tqdm(range(num_epochs)):\n    losses = []\n    for x,y in train_loader:\n        if cuda:\n            x,y=x.cuda(),y.cuda()\n            optimizer.zero_grad()\n            outputs=model(x)\n            loss = loss_fn(outputs.squeeze(),y.type(torch.float32))\n            losses.append(loss.item())\n            loss.backward()\n            optimizer.step()\n    print('iter #{}'.format(it),'Loss:',sum(losses)/len(losses))\n    ","metadata":{"execution":{"iopub.status.busy":"2024-11-03T17:40:06.193996Z","iopub.execute_input":"2024-11-03T17:40:06.194564Z","iopub.status.idle":"2024-11-03T17:44:08.196662Z","shell.execute_reply.started":"2024-11-03T17:40:06.194518Z","shell.execute_reply":"2024-11-03T17:44:08.195558Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_439/3240475993.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\nPlease use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n  for it in tqdm(range(num_epochs)):\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/128 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"719a9e1624a84d1ea507c98f9f393c2a"}},"metadata":{}},{"name":"stdout","text":"iter #0 Loss: 11.071891653961336\niter #1 Loss: 4.751887458532595\niter #2 Loss: 2.4783561961905\niter #3 Loss: 1.7213862833335314\niter #4 Loss: 1.3460121818151571\niter #5 Loss: 1.1286294325656698\niter #6 Loss: 0.9910669817688501\niter #7 Loss: 0.9001742805623766\niter #8 Loss: 0.8372699086587441\niter #9 Loss: 0.7922346216773019\niter #10 Loss: 0.759384210982601\niter #11 Loss: 0.7347322258776819\niter #12 Loss: 0.71584734585382\niter #13 Loss: 0.7015986476982305\niter #14 Loss: 0.6905528691214353\niter #15 Loss: 0.6819392146192832\niter #16 Loss: 0.6749572255435934\niter #17 Loss: 0.6695353003020214\niter #18 Loss: 0.665907263150675\niter #19 Loss: 0.6629372952023739\niter #20 Loss: 0.6604591210557119\niter #21 Loss: 0.6586626301032638\niter #22 Loss: 0.6575523369430285\niter #23 Loss: 0.6567973127673725\niter #24 Loss: 0.6558209972333182\niter #25 Loss: 0.6549199617226716\niter #26 Loss: 0.654080422547868\niter #27 Loss: 0.6535242947225038\niter #28 Loss: 0.6520977712373444\niter #29 Loss: 0.6510404731870303\niter #30 Loss: 0.6494892833347853\niter #31 Loss: 0.6473411117789104\niter #32 Loss: 0.6451534272979964\niter #33 Loss: 0.6422566471214827\niter #34 Loss: 0.6386733193158498\niter #35 Loss: 0.6346943463165748\niter #36 Loss: 0.6302360542837133\niter #37 Loss: 0.6241475799437707\niter #38 Loss: 0.6173871996136486\niter #39 Loss: 0.6106921261185922\niter #40 Loss: 0.6028561913952004\niter #41 Loss: 0.5942286040425906\niter #42 Loss: 0.5854992629383421\niter #43 Loss: 0.5764187347087159\niter #44 Loss: 0.5672370325868505\niter #45 Loss: 0.557726509188335\niter #46 Loss: 0.5477582215506414\niter #47 Loss: 0.538584242201396\niter #48 Loss: 0.5292464222777918\niter #49 Loss: 0.5193670527054574\niter #50 Loss: 0.5103714317461561\niter #51 Loss: 0.5015133776640529\niter #52 Loss: 0.49303043493764653\niter #53 Loss: 0.48454471267192495\niter #54 Loss: 0.4771667213609376\niter #55 Loss: 0.46959734692942673\niter #56 Loss: 0.46301197139593553\niter #57 Loss: 0.45626848743197884\niter #58 Loss: 0.45061049504479783\niter #59 Loss: 0.44445219110262574\niter #60 Loss: 0.4392668380009644\niter #61 Loss: 0.4341037830120416\niter #62 Loss: 0.42916602964706835\niter #63 Loss: 0.424769565084864\niter #64 Loss: 0.42042758678875597\niter #65 Loss: 0.41617437569320503\niter #66 Loss: 0.4124526863132939\niter #67 Loss: 0.40877431553556837\niter #68 Loss: 0.4052319940425418\niter #69 Loss: 0.4018448032438755\niter #70 Loss: 0.3987161892130593\niter #71 Loss: 0.3954252254047672\niter #72 Loss: 0.39293932510057683\niter #73 Loss: 0.3898768151358602\niter #74 Loss: 0.3874023721794489\niter #75 Loss: 0.38482741686293315\niter #76 Loss: 0.38226445176199003\niter #77 Loss: 0.38018348555879544\niter #78 Loss: 0.37776151668223634\niter #79 Loss: 0.37553609240100466\niter #80 Loss: 0.3736473578146569\niter #81 Loss: 0.3716660866390933\niter #82 Loss: 0.3697487855245014\niter #83 Loss: 0.3681265539702425\niter #84 Loss: 0.36629195660730907\niter #85 Loss: 0.3646366708737037\niter #86 Loss: 0.36316415648623773\niter #87 Loss: 0.36145070520451833\niter #88 Loss: 0.35999434299502275\niter #89 Loss: 0.3585928327730162\niter #90 Loss: 0.3573497528503389\niter #91 Loss: 0.35602014954320066\niter #92 Loss: 0.35456162207017694\niter #93 Loss: 0.3534141508531449\niter #94 Loss: 0.35215927751233733\niter #95 Loss: 0.3510752254293352\niter #96 Loss: 0.3499518958142566\niter #97 Loss: 0.34876772422854063\niter #98 Loss: 0.34792397695068783\niter #99 Loss: 0.3468162051312209\niter #100 Loss: 0.34568425184730345\niter #101 Loss: 0.3448405542652014\niter #102 Loss: 0.34406960458698005\niter #103 Loss: 0.3430287420825305\niter #104 Loss: 0.3421648106901779\niter #105 Loss: 0.34141184062446434\niter #106 Loss: 0.3406336166078064\niter #107 Loss: 0.3398492177239227\niter #108 Loss: 0.33902891307388466\niter #109 Loss: 0.3383679273089176\niter #110 Loss: 0.33748437604171977\niter #111 Loss: 0.3368368100582948\niter #112 Loss: 0.3362058021960222\niter #113 Loss: 0.3355942244457109\niter #114 Loss: 0.33481888970369617\niter #115 Loss: 0.33436782007592586\niter #116 Loss: 0.33358201772201485\niter #117 Loss: 0.33309299443957163\niter #118 Loss: 0.33238421660389394\niter #119 Loss: 0.33187412285260137\niter #120 Loss: 0.33143263349905233\niter #121 Loss: 0.3308605187132879\niter #122 Loss: 0.3303030296252464\niter #123 Loss: 0.3296367287408882\niter #124 Loss: 0.3293225165021601\niter #125 Loss: 0.32866130495056284\niter #126 Loss: 0.3280586095971202\niter #127 Loss: 0.3277490790460618\n","output_type":"stream"}]},{"cell_type":"code","source":"c=0\nuw=0\niw=0\nfor name,param in model.named_parameters():\n    if param.requires_grad:\n        print(name,param.data)\n        if c == 0:\n            uw = param.data\n            c+=1\n        else:\n            iw=param.data\n            ","metadata":{"execution":{"iopub.status.busy":"2024-11-03T17:44:08.198102Z","iopub.execute_input":"2024-11-03T17:44:08.198463Z","iopub.status.idle":"2024-11-03T17:44:08.326559Z","shell.execute_reply.started":"2024-11-03T17:44:08.198424Z","shell.execute_reply":"2024-11-03T17:44:08.325502Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"user_factors.weight tensor([[ 1.5080,  1.3075,  1.4231,  ...,  0.6003,  1.2367,  1.8915],\n        [ 1.9910,  1.3721,  0.2084,  ...,  0.5512,  0.9778,  0.9047],\n        [-1.6259,  1.4564,  0.5056,  ...,  0.4476, -0.5610,  0.0945],\n        ...,\n        [ 1.3315, -1.1745,  1.1458,  ...,  1.4891,  0.1635,  1.0942],\n        [ 1.0873,  0.7844,  0.9002,  ...,  1.7296,  0.5573,  0.2509],\n        [ 0.2308,  1.2090,  0.6518,  ...,  1.2877,  0.9109,  0.8331]],\n       device='cuda:0')\nitem_factors.weight tensor([[0.4327, 0.7222, 0.4932,  ..., 0.5978, 0.7145, 0.2517],\n        [0.7540, 0.5026, 0.2385,  ..., 0.2425, 0.7110, 0.6596],\n        [0.3186, 0.2377, 0.4034,  ..., 0.4666, 0.5506, 0.5420],\n        ...,\n        [0.3897, 0.3518, 0.3828,  ..., 0.3466, 0.3859, 0.3647],\n        [0.4763, 0.4342, 0.4111,  ..., 0.3908, 0.4002, 0.4058],\n        [0.4011, 0.4120, 0.3887,  ..., 0.3779, 0.4234, 0.3901]],\n       device='cuda:0')\n","output_type":"stream"}]},{"cell_type":"code","source":"trained_movie_embeddings=model.item_factors.weight.data.cpu().numpy()","metadata":{"execution":{"iopub.status.busy":"2024-11-03T17:44:08.328024Z","iopub.execute_input":"2024-11-03T17:44:08.328585Z","iopub.status.idle":"2024-11-03T17:44:08.334698Z","shell.execute_reply.started":"2024-11-03T17:44:08.328530Z","shell.execute_reply":"2024-11-03T17:44:08.333465Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"trained_movie_embeddings","metadata":{"execution":{"iopub.status.busy":"2024-11-03T17:44:08.338688Z","iopub.execute_input":"2024-11-03T17:44:08.339135Z","iopub.status.idle":"2024-11-03T17:44:08.348979Z","shell.execute_reply.started":"2024-11-03T17:44:08.339084Z","shell.execute_reply":"2024-11-03T17:44:08.347802Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"array([[0.43268162, 0.7221894 , 0.49317485, ..., 0.59776694, 0.71447337,\n        0.2517133 ],\n       [0.75398797, 0.50258625, 0.23853864, ..., 0.242501  , 0.71096987,\n        0.659569  ],\n       [0.31863937, 0.23769757, 0.40336943, ..., 0.46662107, 0.55060434,\n        0.5419912 ],\n       ...,\n       [0.38965592, 0.3517531 , 0.38275376, ..., 0.34655687, 0.3858927 ,\n        0.3647114 ],\n       [0.47629598, 0.43420237, 0.4110809 , ..., 0.3908073 , 0.400188  ,\n        0.40581518],\n       [0.40105006, 0.41203392, 0.3887285 , ..., 0.37793687, 0.42339626,\n        0.39014566]], dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.cluster import KMeans\nkmeans=KMeans (n_clusters=10, random_state=0).fit(trained_movie_embeddings)","metadata":{"execution":{"iopub.status.busy":"2024-11-03T17:44:08.350422Z","iopub.execute_input":"2024-11-03T17:44:08.350897Z","iopub.status.idle":"2024-11-03T17:44:09.529892Z","shell.execute_reply.started":"2024-11-03T17:44:08.350841Z","shell.execute_reply":"2024-11-03T17:44:09.528858Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"for cluster in range(11):\n    print(\"Cluster #{}\".format(cluster))\n    movs=[]\n    for movidx in np.where(kmeans.labels_ == cluster)[0]:\n        movid=train_set.idx2movieid[movidx]\n        #rat_count=ratings_df.loc[ratings_df['movieId']== movid].count()[0]\n        rat_count = ratings_df.loc[ratings_df['movieId'] == movid].count().iloc[0]\n        movs.append((movie_names[movid],rat_count))\n    for mov in sorted(movs, key=lambda tup: tup[1], reverse=True)[:10]:\n        print('\\t', mov[0])\n","metadata":{"execution":{"iopub.status.busy":"2024-11-03T17:59:55.148006Z","iopub.execute_input":"2024-11-03T17:59:55.149044Z","iopub.status.idle":"2024-11-03T18:00:05.504041Z","shell.execute_reply.started":"2024-11-03T17:59:55.148996Z","shell.execute_reply":"2024-11-03T18:00:05.502855Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Cluster #0\n\t Forrest Gump (1994)\n\t Shawshank Redemption, The (1994)\n\t Silence of the Lambs, The (1991)\n\t Matrix, The (1999)\n\t Star Wars: Episode IV - A New Hope (1977)\n\t Star Wars: Episode V - The Empire Strikes Back (1980)\n\t Usual Suspects, The (1995)\n\t Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)\n\t Lord of the Rings: The Fellowship of the Ring, The (2001)\n\t Star Wars: Episode VI - Return of the Jedi (1983)\nCluster #1\n\t Jurassic Park (1993)\n\t Terminator 2: Judgment Day (1991)\n\t Toy Story (1995)\n\t Independence Day (a.k.a. ID4) (1996)\n\t Apollo 13 (1995)\n\t Fugitive, The (1993)\n\t Batman (1989)\n\t Aladdin (1992)\n\t True Lies (1994)\n\t Lion King, The (1994)\nCluster #2\n\t Star Wars: Episode I - The Phantom Menace (1999)\n\t Twister (1996)\n\t Crimson Tide (1995)\n\t American Pie (1999)\n\t Happy Gilmore (1996)\n\t Avatar (2009)\n\t Matrix Reloaded, The (2003)\n\t Armageddon (1998)\n\t Star Wars: Episode II - Attack of the Clones (2002)\n\t Contact (1997)\nCluster #3\n\t Mask, The (1994)\n\t Mrs. Doubtfire (1993)\n\t Ghostbusters (a.k.a. Ghost Busters) (1984)\n\t Home Alone (1990)\n\t Clueless (1995)\n\t Cliffhanger (1993)\n\t While You Were Sleeping (1995)\n\t Back to the Future Part III (1990)\n\t Airplane! (1980)\n\t Back to the Future Part II (1989)\nCluster #4\n\t Cable Guy, The (1996)\n\t Batman & Robin (1997)\n\t Striptease (1996)\n\t Godzilla (1998)\n\t Superman III (1983)\n\t Super Mario Bros. (1993)\n\t Honey, I Blew Up the Kid (1992)\n\t Grease 2 (1982)\n\t Another Stakeout (1993)\n\t Superman IV: The Quest for Peace (1987)\nCluster #5\n\t Ace Ventura: Pet Detective (1994)\n\t Pretty Woman (1990)\n\t Dumb & Dumber (Dumb and Dumber) (1994)\n\t Waterworld (1995)\n\t Harry Potter and the Chamber of Secrets (2002)\n\t Mummy, The (1999)\n\t Demolition Man (1993)\n\t Pirates of the Caribbean: Dead Man's Chest (2006)\n\t Bruce Almighty (2003)\n\t Harry Potter and the Goblet of Fire (2005)\nCluster #6\n\t Braveheart (1995)\n\t Titanic (1997)\n\t Beautiful Mind, A (2001)\n\t Minority Report (2002)\n\t Catch Me If You Can (2002)\n\t Green Mile, The (1999)\n\t Rain Man (1988)\n\t 300 (2007)\n\t Bridget Jones's Diary (2001)\n\t Love Actually (2003)\nCluster #7\n\t Schindler's List (1993)\n\t Fargo (1996)\n\t E.T. the Extra-Terrestrial (1982)\n\t Willy Wonka & the Chocolate Factory (1971)\n\t Breakfast Club, The (1985)\n\t Shining, The (1980)\n\t Donnie Darko (2001)\n\t Four Weddings and a Funeral (1994)\n\t Casablanca (1942)\n\t Being John Malkovich (1999)\nCluster #8\n\t Ghost (1990)\n\t Net, The (1995)\n\t Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) (2001)\n\t Broken Arrow (1996)\n\t Charlie's Angels (2000)\n\t Die Hard 2 (1990)\n\t Legally Blonde (2001)\n\t Sound of Music, The (1965)\n\t Miss Congeniality (2000)\n\t Chronicles of Narnia: The Lion, the Witch and the Wardrobe, The (2005)\nCluster #9\n\t Pulp Fiction (1994)\n\t Fight Club (1999)\n\t American Beauty (1999)\n\t Seven (a.k.a. Se7en) (1995)\n\t Godfather, The (1972)\n\t Sixth Sense, The (1999)\n\t Twelve Monkeys (a.k.a. 12 Monkeys) (1995)\n\t Memento (2000)\n\t Alien (1979)\n\t Inception (2010)\nCluster #10\n","output_type":"stream"}]}]}